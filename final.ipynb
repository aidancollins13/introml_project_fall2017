{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#creating whole dataset\n",
    "seventeen = pd.read_json(\"https://missingmigrants.iom.int/global-figures/2017/json\")\n",
    "sixteen = pd.read_json(\"https://missingmigrants.iom.int/global-figures/2016/json\")\n",
    "fifteen = pd.read_json(\"https://missingmigrants.iom.int/global-figures/2015/json\")\n",
    "fourteen = pd.read_json(\"https://missingmigrants.iom.int/global-figures/2014/json\")\n",
    "\n",
    "frames = [seventeen,sixteen,fifteen,fourteen]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(frames)\n",
    "#cleaning data\n",
    "df = df.replace('', 0,regex=True)\n",
    "df = df.replace('nan', 0, regex=True)\n",
    "df.drop(['Information Source'])\n",
    "df = df[df['Web ID'] != 42424] #drops row with -1 as number of survivors\n",
    "\n",
    "\n",
    "df['Reported Date'] = pd.to_datetime(df['Reported Date'])\n",
    "df['total people'] = pd.to_numeric(df['Number of survivors']) + pd.to_numeric(df['Total Dead and Missing'])\n",
    "df['percent female'] = (pd.to_numeric(df['Number of Female'])/ df['total people']).fillna(0)\n",
    "df['percent male'] =  (pd.to_numeric(df['Number of Male'])/ df['total people']).fillna(0)\n",
    "df['percent kids'] =  (pd.to_numeric(df['Number of Children']) / df['total people']).fillna(0)\n",
    "df['month'] = df['Reported Date'].dt.month\n",
    "df['day'] = df['Reported Date'].dt.day\n",
    "\n",
    "R = 6371\n",
    "df['x'] = df['Location'].apply(lambda latLong: R*math.cos(float(latLong.split(\", \")[0]))*math.cos(float(latLong.split(\", \")[1])))\n",
    "df['y'] = df['Location'].apply(lambda latLong: R*math.cos(float(latLong.split(\", \")[0]))*math.sin(float(latLong.split(\", \")[1])))\n",
    "df['z'] = df['Location'].apply(lambda latLong: R*math.sin(float(latLong.split(\", \")[0])))\n",
    "\n",
    "# the index will help us get back from number to category later\n",
    "##df['UNSD Geographical Grouping'], geoIndex = pd.Series(df['UNSD Geographical Grouping']).factorize()\n",
    "#df['Migrant Route'], migrantIndex = pd.Series(df['Migrant Route']).factorize()\n",
    "#df['Region of Incident'], regionIndex = pd.Series(df['Region of Incident']).factorize()\n",
    "# one hot coding\n",
    "ohc_UNSD = pd.get_dummies(df['UNSD Geographical Grouping'],prefix='UNSD')\n",
    "ohc_Route = pd.get_dummies(df['Migrant Route'],prefix='Route')\n",
    "ohc_Region = pd.get_dummies(df['Region of Incident'],prefix='Region')\n",
    "\n",
    "df = df.join(ohc_UNSD)\n",
    "df = df.join(ohc_Region)\n",
    "df = df.join(ohc_Route)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#separating data\n",
    "fourteen = df[(df['Reported Date'] >= '2014-01-01') & (df['Reported Date'] < '2015-01-01')]\n",
    "fifteen = df[(df['Reported Date'] >= '2015-01-01') & (df['Reported Date'] < '2016-01-01')]\n",
    "sixteen = df[(df['Reported Date'] >= '2016-01-01') & (df['Reported Date'] < '2017-01-01')]\n",
    "seventeen = df[(df['Reported Date'] >= '2017-01-01') & (df['Reported Date'] < '2018-01-01')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_data = np.concatenate((np.array(fourteen),np.array(fifteen),np.array(sixteen),np.array(seventeen)))\n",
    "# np.random.shuffle(total_data)\n",
    "# y = total_data[:,11].astype(int) / (total_data[:,14].astype(int) + total_data[:,11].astype(int)) \n",
    "# # y is what we predict -- total sruvivors over total survivors+missing and dead \n",
    "# y = np.nan_to_num(y)\n",
    "# y = (100*y).astype(int)\n",
    "# # x is the parts of the data we are using to predict Location, route, region, and Geographical Grouping\n",
    "# x[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train = 2000\n",
    "# x_tr = x[:train,:]\n",
    "# y_tr = y[:train]\n",
    "# x_ts = x[train:,:]\n",
    "# y_ts = y[train:]\n",
    "# from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:  0.116304628372\n",
      "test:  0.103028043632\n",
      "[ -1.40149394e-01   2.38733457e-02  -1.32286811e-01   9.10707121e-03\n",
      "  -3.47441045e-01   1.12078274e+01   3.95012134e+00  -2.53361631e+00\n",
      "  -4.16267447e+00   3.07913398e+01   3.11484148e+00  -6.32334090e+00\n",
      "  -1.51877285e+00  -9.75164231e+00  -1.15723285e+00  -2.08666862e+00\n",
      "  -1.65148514e+01  -6.45324248e+00   3.08771507e+00   1.47455951e+00\n",
      "  -6.00257206e-01  -1.24908888e+00  -1.27501632e+00   7.58805425e+00\n",
      "  -7.85246284e-01   2.02657014e+01   6.86475485e-01  -5.51238123e+00\n",
      "   2.09380657e+00  -1.00158633e+00  -6.14156851e+00  -1.89199379e+00\n",
      "  -3.25554108e+00  -1.24886721e+01  -6.92094682e-01   3.26370719e+00\n",
      "  -2.12866092e+00  -1.56808854e+00  -2.31257048e+00  -6.60673515e+00\n",
      "  -9.14175813e+00   3.99650850e+00  -3.91572551e+00  -2.11344377e+01\n",
      "   3.23356894e+00  -1.19345074e+01   1.45839367e+01  -3.87185458e+00\n",
      "  -1.33385919e+01   5.51694594e+01  -4.50202798e+00   2.38732834e+00\n",
      "  -1.04450441e+00]\n",
      "\n",
      "train:  0.113125764802\n",
      "test:  0.112806386668\n",
      "[ -1.33959625e-01   2.94284157e-02  -1.28021053e-01  -4.46368563e-03\n",
      "  -3.12288322e-01   1.01908947e+01   6.48331130e+00  -2.97780749e+00\n",
      "  -3.95417992e+00   3.57915348e+01   2.78094512e+00  -6.33384144e+00\n",
      "  -2.16589722e+00  -9.89704501e+00  -1.64263725e+00  -3.26520471e+00\n",
      "  -1.65184177e+01  -7.28641496e+00   3.95803802e+00   1.47956041e+00\n",
      "  -2.28189705e+00  -2.53038450e+00  -1.83055709e+00   5.90576578e+00\n",
      "  -5.03106755e-01   2.07201147e+01  -2.02716823e-01  -4.90257157e+00\n",
      "   1.53110549e+00  -6.56529495e-01  -5.64723453e+00  -1.35323614e+00\n",
      "  -3.80898574e+00  -1.23106274e+01  -1.77586952e-01   3.30003211e+00\n",
      "  -1.89442264e+00  -1.82731402e+00  -8.98588643e-01  -6.16811465e+00\n",
      "  -8.69708291e+00   3.74271831e+00  -4.44681313e+00  -2.22623621e+01\n",
      "   3.17308914e+00  -1.20964297e+01   1.42142590e+01  -3.63439603e+00\n",
      "  -1.36339505e+01   5.65997903e+01  -4.21426695e+00   1.38471627e+00\n",
      "  -1.23525449e+00]\n",
      "\n",
      "train:  0.1126032444\n",
      "test:  0.114908883902\n",
      "[ -1.36322381e-01   2.61502151e-02  -1.28961940e-01  -1.67726862e-03\n",
      "  -3.32750382e-01   1.11029268e+01   6.50580141e+00  -2.30619938e+00\n",
      "  -3.57981520e+00   2.82841034e+01   2.10825040e+00  -6.00301287e+00\n",
      "  -1.62289832e+00  -9.65579536e+00  -1.70036988e+00  -1.59684533e+00\n",
      "  -1.53280488e+01  -6.66564534e+00   3.33166921e+00   1.70232655e+00\n",
      "  -1.45174981e+00  -1.59940572e+00  -1.52529173e+00   8.25288997e+00\n",
      "  -6.67590412e-01   2.24349651e+01   1.35752598e-01  -5.65544661e+00\n",
      "   1.70464846e+00  -1.23265233e+00  -5.94124051e+00  -1.78098874e+00\n",
      "  -3.03349954e+00  -1.29400084e+01  -1.27875049e+00   2.04408696e+00\n",
      "  -2.04216613e+00  -1.55159826e+00  -1.86519738e+00  -5.63024776e+00\n",
      "  -8.45028471e+00   3.49496011e+00  -3.71099715e+00  -2.30812873e+01\n",
      "   2.86972413e+00  -1.29112682e+01   1.64874680e+01  -3.80125513e+00\n",
      "  -1.30527313e+01   5.59064351e+01  -3.92949419e+00   3.27628844e-01\n",
      "  -1.10185489e+00]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def initTest(df):\n",
    "    y = np.array((pd.to_numeric(df['Number of survivors']) / df['total people']).fillna(0))\n",
    "    y = np.nan_to_num(y)\n",
    "    y[y == np.abs(np.inf)] = 0\n",
    "    \n",
    "    y = (100*y).astype(int)\n",
    "\n",
    "\n",
    "    x = np.array(df[['percent female', 'percent kids', 'percent male', 'day','month']])\n",
    "    x = np.column_stack((x,np.array(df.loc[:,'UNSD_0':])))\n",
    "    \n",
    "    x = np.nan_to_num(x)\n",
    "    x[:,0] = (100*x[:,0]).astype(int)\n",
    "    x[:,1] = (100*x[:,1]).astype(int)\n",
    "    x[:,2] = (100*x[:,2]).astype(int)\n",
    "    \n",
    "    rs = ShuffleSplit(n_splits=3, test_size=.25, random_state=0)\n",
    "\n",
    "    for train_index, test_index in rs.split(x):\n",
    "        regr = linear_model.LinearRegression()\n",
    "        regr.fit(x[train_index],y[train_index])\n",
    "        print(\"train: \", regr.score(x[train_index],y[train_index]) )\n",
    "        print(\"test: \", regr.score(x[test_index],y[test_index]))\n",
    "        print(regr.coef_)\n",
    "        print()\n",
    "    print()\n",
    "initTest(sixteen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "onlyUS = df[df['UNSD Geographical Grouping'] == geoIndex.get_loc('Northern America')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initTest(onlyUS)\n",
    "initTest(df)\n",
    "initTest(df[df['UNSD Geographical Grouping'] == geoIndex.get_loc('Central America')])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
